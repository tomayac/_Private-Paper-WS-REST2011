% THIS IS SIGPROC-SP.TEX - VERSION 3.1
% WORKS WITH V3.2SP OF ACM_PROC_ARTICLE-SP.CLS
% APRIL 2009
%
% It is an example file showing how to use the 'acm_proc_article-sp.cls' V3.2SP
% LaTeX2e document class file for Conference Proceedings submissions.
% ----------------------------------------------------------------------------------------------------------------
% This .tex file (and associated .cls V3.2SP) *DOES NOT* produce:
%       1) The Permission Statement
%       2) The Conference (location) Info information
%       3) The Copyright Line with ACM data
%       4) Page numbering
% ---------------------------------------------------------------------------------------------------------------
% It is an example which *does* use the .bib file (from which the .bbl file
% is produced).
% REMEMBER HOWEVER: After having produced the .bbl file,
% and prior to final submission,
% you need to 'insert'  your .bbl file into your source .tex file so as to provide
% ONE 'self-contained' source file.
%
% Questions regarding SIGS should be sent to
% Adrienne Griscti ---> griscti@acm.org
%
% Questions/suggestions regarding the guidelines, .tex and .cls files, etc. to
% Gerald Murray ---> murray@hq.acm.org
%
% For tracking purposes - this is V3.1SP - APRIL 2009

\documentclass{acm_proc_article-sp}

%\usepackage{url}
\usepackage[hyphens]{url}
\usepackage{textcomp}

\begin{document}

\title{Fulfilling the Hypermedia Constraint Via HTTP OPTIONS, The HTTP Vocabulary In RDF, And Link Headers}
%
% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

\numberofauthors{2} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%
\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
\alignauthor Thomas Steiner\\
       \affaddr{Universitat Polit{\'e}cnica de Catalunya}\\
       \affaddr{Department LSI}\\
       \affaddr{08034 Barcelona, Spain}\\
       \email{tsteiner@lsi.upc.edu}
\alignauthor Jan Algermissen\\
       \affaddr{NORD Software Consulting}\\
       \affaddr{Kriemhildstra\ss e 7}\\
       \affaddr{22559 Hamburg}\\
       \email{info@nordsc.com}
}
% Just remember to make sure that the TOTAL number of authors
% is the number that will appear on the first page PLUS the
% number that will appear in the \additionalauthors section.

\maketitle
\begin{abstract}
One of the main REST design principles is the focus on media types as the core of contracts on the Web. However, not always is the service designer free to select the most appropriate media type for a task, sometimes a generic media type like application/rdf+xml with no defined hypermedia controls at all has to be chosen. With this position paper we present a way how the hypermedia constraint from REST can still be fulfilled using a combination of Link headers, the OPTIONS method, and the HTTP Vocabulary in RDF. 
\end{abstract}

% A category with the (minimum) three required fields
\category{H.3}{Information Storage and Retrieval}{On-line Information Services}

\terms{Experimentation}

\keywords{REST, Hypermedia Constraint, HATEOAS, HTTP} % NOT required for Proceedings

\section{Introduction}\label{sec:introduction}
In one of his blog posts\footnote{\url{http://roy.gbiv.com/untangled/2008/rest-apis-must-be-hypertext-driven}} Roy T. Fielding complains about the common practice to call HTTP-based interfaces REST APIs. Fielding emphasis that REST APIs must be hypertext driven. In a comment on this post he defines \textit{hypertext} (and compares it to the term \textit{hypermedia}) as follows:
\begin{quote}
When I say hypertext, I mean the simultaneous presentation of information and controls such that the information becomes the affordance through which the user (or automaton) obtains choices and selects actions. Hypermedia is just an expansion on what text means to include temporal anchors within a media stream; most researchers have dropped the distinction. Hypertext does not need to be HTML on a browser. Machines can follow links when they understand the data format and relationship types.
\end{quote}
Hence, the essential constraint of REST is the hypermedia constraint, which in the Richardson Maturity Model (see the following section \ref{sec:rmm}) is described as the last step towards the full glory of REST.

\subsection{Richardson Maturity Model (RMM)}\label{sec:rmm}
In the Richardson Maturity Model\footnote{\url{http://martinfowler.com/articles/richardsonMaturityModel.html}} (RMM) Leonard Richardson describes four levels towards true REST. Level zero is about tunneling all data through HTTP with only one HTTP method to just one endpoint usually using Remote Procedure Calls (RPC) and neglecting any mechanisms of the Web. Level one introduces resources, so rather than talking to just one endpoint, several endpoints are used. Level two switches from just one HTTP method to more adequate methods, oftentimes aligned to the four functions of persistent storage, CREATE, READ, UPDATE, DELETE (CRUD). In addition to different HTTP methods, also different HTTP status codes are used in order to signal states. Finally level three introduces hypermedia controls that give an answer to the question "\textit{where} can one go next" and "\textit{what} can one do next" after each request in form of links. An API designed along these principles can be autodiscovered by a user agent by simply following her nose.

The authors, however, prefer not to use the RMM because it implies that the three lower levels induce a researched set of properties that imply that there is a known/assessable value in applying only a subset of the REST constraints.

\subsection{On the Hypermedia Constraint}\label{sec:hateoas}
We have cited Fielding's to-the-point definition of \textit{hypermedia}/\textit{hypertext} above. Next, we define \textit{application state}. The problem with \textit{application state}, however, is that it is understood differently by different people. We tend to a definition that is explained best with the example of pagination on a search engine results page. Assume each page contained a link to its direct successor and predecessor. If the current page has a link to page seven and page nine, there can be directly implied that the current page must be page eight, if, and only if, the relations of the links are known beforehand. In consequence the application is in state eight, without the explicit need to serialize this state somehow. The state machine of an application is not defined by the service, but by the user agent. In other words, the application comes into being by the choices the user agent makes, not by what the service intended.

\section{Hypermedia Controls}\label{sec:currenthateoas}
The hypermedia constraint is fulfilled by embedding hypermedia controls (e.g., links, forms) in the representations made available to the client. There is no standard way to represent these controls, however, some common practices.

\subsection{Atom Syndication Format (RFC4287)}\label{sec:atom}
In the Atom Syndication Format \cite{Atom:Synd} there is the \texttt{atom:link} element that defines a reference from an entry or feed to a Web resource. The (simplified) structure of the element is as follows:
\begin{verbatim}
atomLink =
  element atom:link {
    attribute href { atomUri },
    attribute rel { atomNCName | atomUri }?,
    attribute type { atomMediaType }?,
    attribute hreflang { atomLanguageTag }?,
    attribute title { text }?,
    attribute length { text }?}
\end{verbatim}
The \texttt{@href} attribute must contain the link's IRI (the response to the question "\textit{where} can one go next"). The response to the question "\textit{what} can one do next" can (not must) be given in the link's \texttt{@rel} attribute. Its value can be a pre-defined value\footnote{The current list of pre-defined link relations is maintained by the IANA at \url{http://www.iana.org/assignments/link-relations/link-relations.xhtml.}}, or an IRI for custom link relations.

\subsection{Google Data Protocol}\label{sec:gdata}
The Atom Publishing Protocol\cite{Atom:Pub} is an application-level protocol for publishing and editing Web resources. The Google Data Protocol\cite{Google:Data} extends the Atom Publishing Protocol for processing queries, authentication, and batch requests. It is based on HTTP transfer of Atom-formatted representations. There are two serializations available: XML and JSON\footnote{\url{http://code.google.com/apis/gdata/docs/json.html}}. The structure of the XML serialization is the same as in \ref{sec:atom}, the structure of the JSON serialization can be seen below:
\begin{verbatim}
"link": [{
  "rel": "...",
  "type": "...",
  "href": "..."}]
\end{verbatim}
The elements and attributes of the JSON serialization are a straight-forward mapping of the XML serialization, its advantage is that it is directly usable in JavaScript.

\subsection{(X)HTML With Or Without Forms}\label{sec:xhtml}
A regular human-readable (X)HTML page can serve as a hypermedia control. Contained links and potential surrounding textual information can be understood by humans, while machines can process the links. Forms can give further instructions on the \textit{how} of the next steps. With forms, allowed values for parameters, like, e.g., enumerations can be defined.

\subsection{Form Technologies}\label{sec:formtechs}
We adopt the term "form technologies" from Leonard Richardson\footnote{\url{http://www.crummy.com/writing/speaking/2008-QCon/act3.html}} to reference a subset of description languages and mechanisms that are commonly criticized as being brittle\footnote{See, e.g., \url{http://bitworking.org/news/193/Do-we-need-WADL} for WADL.}. The goal of such form technologies like the Web Application Description Language (WADL)\footnote{\url{http://www.w3.org/Submission/wadl/}}, or RDF Forms\footnote{\url{http://www.markbaker.ca/2003/05/RDF-Forms/}} is to describe the HTTP methods, parameters, and allowed values that are involved during an API request.

\subsection{Media Types}\label{sec:mediatypes}
Media type give detailed insights into \textit{how} to process a representation. They outline which parts of the representation are hypermedia controls and their meaning. If media types are defined to be extensible (i.e., in a way that new data can be added without breaking old user agents that did not expect this new data), they can help decouple a service from its implementation. In order to register a new media type, a registration template can be submitted for review to the IANA. More specific, i.e., exactly not generic media types like \texttt{application/json}, \texttt{application/xml} or \texttt{text/xml}) are an essential aspect of achieving self descriptiveness and are key for implementing truely RESTful APIs.

\subsection{Link Headers}\label{sec:linkheaders}
In the proposed standard documen Web Linking\cite{Link:Headers} Mark Nottingham specifies relation types for Web links and how such links can be used with a Link header field in HTTP. In addition to that the document also defines a registry for link relations (section 6.2.2), therewith updating the relations defined in the Atom Syndication Format. Quoting from \cite{Link:Headers}:
\begin{quote}
The Link entity-header field provides a means for serialising one or more links in HTTP headers.  It is semantically equivalent to the <LINK> element in HTML, as well as the atom:link feed-level element in Atom [RFC4287].
\end{quote}
A concrete example is shown below:
\begin{verbatim}
Link: <http://search.example.org/results/page7>;
    rel="previous"; title="previous results"
Link: <http://search.example.org/results/page9>;
    rel="next"; title="next results"
\end{verbatim}
As outlined in the same example in section \ref{sec:hateoas}, the implication is that the current page is page 8, as the link relations \texttt{previous} and \texttt{next} refer to an ordered series of resources. Link relations are not limited to the set of registered relations, but can be any IRI. If we build the bridge to the world of Linked Data\cite{TimBL:LinkedData} where Tim Berners-Lee defines the four rules for Linked Data, we can see that there, too, URIs play a central role:
\begin{enumerate}
\item Use URIs as names for things.
\item Use HTTP URIs so that people can look up those names.
\item When someone looks up a URI, provide useful information, using the standards (RDF*, SPARQL).
\item Include links to other URIs, so that they can discover more things.
\end{enumerate}
Hence, the idea is to combine link relations with meaningful Linked Data URIs.

\section{HTTP OPTIONS}\label{sec:httpoptions}
HTTP OPTIONS is one of the most basic ways to discover a resource. According to section 5.1.1 of the HTTP/1.1 specification\cite{HTTP:Spec} only the methods GET and HEAD must be supported by all general-purpose servers, all other methods are optional. The specification says about OPTIONS:
\begin{quote}
The OPTIONS method represents a request for information about the communication options available on the request/response chain identified by the Request-URI. [\ldots] A 200 response SHOULD include any header fields that indicate optional features implemented by the server and applicable to that resource (e.g., Allow), possibly including extensions not defined by this specification. The response body, if any, SHOULD also include information about the communication options. The format for such a body is not defined by this specification, but might be defined by future extensions to HTTP.
\end{quote}
OPTIONS is not supported by all servers. The expected behavior can be seen for example on our university domain \url{http://www.upc.edu/}, including out-of-HTTP extensions:
\begin{verbatim}
$ curl  -i -X OPTIONS http://www.upc.edu/
HTTP/1.1 200 OK
Allow: GET, HEAD, POST, PUT, DELETE, OPTIONS, TRACE,
    PROPFIND, PROPPATCH, MKCOL, COPY, [...]
Content-Length: 0
\end{verbatim}

\section{The HTTP Vocabulary in RDF}\label{sec:httpvocab}
The HTTP Vocabulary in RDF\cite{HTTP:RDF} defines a representation of HTTP in Resource Description Framework (RDF)\cite{W3C:RDF}. It is intended to record HTTP(S) request and response messages, including the various headers. Consider the following HTTP request:
\begin{verbatim}
$ curl -i http://dbpedia.org/
    -H "Accept: application/rdf+xml"
\end{verbatim}
Modeled in RDF (in Turtle syntax\footnote{\url{http://www.w3.org/TeamSubmission/turtle/}}, prefixes omitted for the sake of brevity) the request looks like this:
\begin{verbatim}
_:req a http:Request ;
  http:httpVersion "1.1" ;
  http:methodName "GET" ;
  http:mthd <http://www.w3.org/2008/http-
      methods#GET> ;
  http:headers (
    [ http:fieldName "Host";
      http:fieldValue "dbpedia.org";
      http:hdrName <http://www.w3.org/2008/-
          http-header#host> ]
    [ http:fieldName "Accept";
      http:fieldValue "application/rdf+xml";
      http:hdrName <http://www.w3.org/2008/-
          http-header#accept> ]
      ) .
\end{verbatim}

\section{Combining the Technologies}\label{sec:implementation}
Bringing the technologies mentioned above together, we have first Link headers to transparently inject data into a response without touching the body of the HTTP message. Second, we have OPTIONS as a means of discovering a resource on HTTP level. Third, we have the HTTP Vocabulary in RDF, which allows for HTTP communication to be modeled.

In order to test how to fulfill the hypermedia constraint with these technologies, we took an existing Web application of ours\footnote{\url{http://tomayac.com/semwebvid/}}, and converted it into an API with the functionality to automatically annotate YouTube videos in RDF, where the input is a YouTube video ID, and the output an RDF document. In the course of implementing this API, a set of secondary wrapper APIs were implemented as well, one for YouTube video search based on a query, one for Named Entity Extraction (NEE) based on a text fragment, and one for URI Lookup (UL) based on a term. See Figure \ref{fig:overview} for an overview of the structure of the services and the link relations between the service components. We serve the output of the wrapping services with the pseudo media types \texttt{application/prs.atom+json} for YouTube API-based data, with \texttt{application/prs.nee-entity+json} for NEE-based data, and with \texttt{application/prs.ul-entity+json} for UL-based data. The main problem of the API is the output format: the video annotation service must return RDF in one of its serializations, in consequence the media types are \texttt{text/turtle}, or \texttt{application/rdf+xml}. The RDF/XML media type\footnote{\url{http://tools.ietf.org/html/rfc3870}} describes the format, however, no media controls. With our API it is, however, also possible to modify an existing automatically generated RDF annotation of a video in order to correct (via PUT) or delete (via DELETE) it. Hence, there are actions as potential next steps that are not described by the generic RDF/XML media type. This is where Link headers come into play. For the video annotation API these are the Link headers that get sent upon accessing \url{http://localhost/youtube/rdf/3PuHGKnboNY}:
\begin{verbatim}
Link: <http://localhost/youtube/videos/53PuHGKnboNY>;
          rel="related";
          type="application/prs.atom+json";
          title="video metadata"
      <http://localhost/youtube/search/opensearch.xml>;
          rel="search"; title="search",
      <>; rel="edit"; title="delete, modify",
      <>; rel="alternate"; type="application/rdf+xml",
      <>; rel="alternate"; type="text/turtle"   
\end{verbatim}
Complimentary to Link headers, and due to the extensibility of RDF links can also be added in triple form to the actual service output (here and below we have only listed the first from all the Link headers above, prefixes omitted):
\begin{verbatim}
_:link_1 a atom:link ;
  atom:href
    <http://localhost/youtube/videos/53PuHGKnboNY> ;
  atom:rel "related" .
\end{verbatim}
In order to explore the API an OPTIONS call against, e.g., \url{http://localhost/youtube/videos} can be made that returns the following headers and body:
\begin{verbatim}
$ curl -i -X OPTIONS http://localhost/youtube/videos

HTTP/1.1 200 OK
Content-Type: text/turtle; charset=utf-8
Link: <http://localhost/youtube/videos/{video_id}>;
          rel="related"
Allow: GET, HEAD, PUT, DELETE, OPTIONS, PATCH
Content-Length: xx

_:req_1 a http:Request ;
  http:httpVersion "1.1" ;
  http:methodName "GET" ;
  http:mthd <http://www.w3.org/2008/http-
      methods#GET> ;
  exHttp:prefixPath "/youtube/rdf/" ;
  exHttp:suffixPath [
    a api:uriTemplate ;
    a youtube_data_api_tag_yt:videoid ;
  ] ;
  http:headers (
    [ http:fieldName "Host";
      http:fieldValue "localhost";
      http:hdrName <http://www.w3.org/2008/-
          http-header#host> ]
      ) .
\end{verbatim}
User agents can then try to discover the constraints (in this case that the {video\_id} URI template is a YouTube video ID).
\begin{figure}
 \centering
 \includegraphics[width=\linewidth]{statemachine.png}
 \caption{Overview of the API structure with link relations and allowed HTTP method names.}
 \label{fig:overview}
\end{figure}

\section{Conclusion}\label{sec:relatedwork}
We have shown an approach towards fulfilling the hypermedia constraint with the OPTIONS message header and body, where the header contains Link headers, and the body HTTP Vocabulary in RDF triples. The approach has been successfully applied to an API with media type constraints. A criticism of the approach might be that it seems to encourage tight coupling, however, not if API consumers interpret their OPTIONS at run-time. Given the complete Semantic Web stack, automatic reasoning over such service annotations could be possible, and, in addition to that, semantic link relations open to REST the whole Linked Data world. Future work will be to evaluate our approach on more and complexer services, and see how far a consumer can reach with only discovering OPTIONS, following links, and interpreting the results.

%\end{document}  % This is where a 'short' article might terminate

%ACKNOWLEDGMENTS are optional
\section{Acknowledgments}\label{sec:acknowledgments}
Partially funded by EU FP7 I-SEARCH project (ref. 248296).

%
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{sigproc-sp}  % sigproc.bib is the name of the Bibliography in this case
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references
%
% ACM needs 'a single self-contained file'!
%
%APPENDICES are optional

%\appendix
%Appendix A
%\balancecolumns
\end{document}
